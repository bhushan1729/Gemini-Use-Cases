{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U google-generativeai install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\Desktop\\Gemini\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import Markdown\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "# Check if the API_KEY is loaded correctly\n",
    "if api_key is None:\n",
    "    print(\"API_KEY not found in environment\")\n",
    "else:\n",
    "    genai.configure(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 8192)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = genai.get_model('models/gemini-1.5-flash')\n",
    "(model_info.input_token_limit, model_info.output_token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 8192)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = genai.get_model('models/gemini-1.5-pro')\n",
    "(model_info.input_token_limit, model_info.output_token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 8192)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info = genai.get_model('models/gemini-2.0-flash-exp')\n",
    "(model_info.input_token_limit, model_info.output_token_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_tokens: 10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
    "model.count_tokens(\"The quick brown fox jumps over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the classic pangram, containing all 26 letters of the English alphabet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 11\n",
       "candidates_token_count: 19\n",
       "total_token_count: 30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to count number of tokens\n",
    "#### https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Counting_Tokens.ipynb#scrollTo=eqUpyE_E95_w\n",
    "Use the usage_metadata attribute on the response object after calling generate_content.\n",
    "This returns the total number of tokens in both the input and the output: total_token_count.\n",
    "It also returns the token counts of the input and output separately: prompt_token_count (input tokens) and candidates_token_count (output tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generative model\n",
    "genai.configure(api_key=\"AIzaSyAFh8A_lni_FzoSQl0U3AtqbPP4NWWS7-Q\")\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) aims to mimic human cognitive functions like learning, problem-solving, and decision-making.  While different AI systems work in different ways, most share some common underlying principles:\n",
      "\n",
      "**1. Data Collection and Preparation:**\n",
      "\n",
      "* AI algorithms are data-hungry. They learn from vast amounts of data relevant to the task they're designed for. This data can be anything from text and images to sensor readings and financial transactions.\n",
      "* The data needs to be cleaned, processed, and formatted into a usable form for the AI system.  This often involves removing errors, handling missing values, and transforming the data into a structured format.\n",
      "\n",
      "**2. Algorithm Selection and Training:**\n",
      "\n",
      "* The heart of an AI system is its algorithm.  Different algorithms are suited for different tasks.  Some common types include:\n",
      "    * **Machine Learning (ML):** Algorithms that learn patterns from data without explicit programming. This includes:\n",
      "        * **Supervised Learning:**  The algorithm is trained on labeled data (e.g., images tagged with the objects they depict).  It learns to predict the labels for new, unseen data.\n",
      "        * **Unsupervised Learning:** The algorithm finds patterns in unlabeled data (e.g., clustering similar customers based on their purchasing behavior).\n",
      "        * **Reinforcement Learning:** The algorithm learns through trial and error, receiving rewards for desired actions and penalties for undesired ones.\n",
      "    * **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers to learn complex patterns from data.\n",
      "    * **Natural Language Processing (NLP):** Algorithms designed to understand and process human language.\n",
      "    * **Computer Vision:** Algorithms that enable computers to \"see\" and interpret images and videos.\n",
      "* Training involves feeding the chosen algorithm with the prepared data. The algorithm adjusts its internal parameters to minimize errors and improve its performance on the task.\n",
      "\n",
      "**3. Evaluation and Deployment:**\n",
      "\n",
      "* After training, the AI system's performance is evaluated on a separate dataset that it hasn't seen before. This helps ensure it can generalize to new data.\n",
      "* Once the performance is satisfactory, the AI system can be deployed to perform its intended task, whether it's recommending products, translating languages, or driving a car.\n",
      "\n",
      "**4. Ongoing Monitoring and Refinement:**\n",
      "\n",
      "* AI systems are not static.  They need to be continuously monitored and refined as new data becomes available or the environment changes. This might involve retraining the model with updated data, adjusting parameters, or even choosing a different algorithm.\n",
      "\n",
      "\n",
      "**Simplified Analogy:**\n",
      "\n",
      "Imagine teaching a dog a trick.  You show the dog what you want it to do (data), give it commands and rewards/corrections (training the algorithm), and then test it to see if it learned the trick (evaluation).  Over time, with more practice and feedback, the dog gets better at the trick (ongoing refinement).\n",
      "\n",
      "**Key Considerations:**\n",
      "\n",
      "* **Bias:** AI systems can inherit biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
      "* **Explainability:** Understanding how an AI system arrives at its decisions is crucial for trust and accountability.\n",
      "* **Ethical Implications:**  The increasing use of AI raises ethical concerns about privacy, job displacement, and autonomous weapons systems.\n",
      "\n",
      "\n",
      "This explanation provides a general overview. The specifics of how an AI system works can vary greatly depending on its purpose, the chosen algorithms, and the data it's trained on.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Artificial intelligence (AI) aims to mimic human cognitive functions like learning, problem-solving, and decision-making.  While different AI systems work in different ways, most share some common underlying principles:\n",
       "\n",
       "**1. Data Collection and Preparation:**\n",
       "\n",
       "* AI algorithms are data-hungry. They learn from vast amounts of data relevant to the task they're designed for. This data can be anything from text and images to sensor readings and financial transactions.\n",
       "* The data needs to be cleaned, processed, and formatted into a usable form for the AI system.  This often involves removing errors, handling missing values, and transforming the data into a structured format.\n",
       "\n",
       "**2. Algorithm Selection and Training:**\n",
       "\n",
       "* The heart of an AI system is its algorithm.  Different algorithms are suited for different tasks.  Some common types include:\n",
       "    * **Machine Learning (ML):** Algorithms that learn patterns from data without explicit programming. This includes:\n",
       "        * **Supervised Learning:**  The algorithm is trained on labeled data (e.g., images tagged with the objects they depict).  It learns to predict the labels for new, unseen data.\n",
       "        * **Unsupervised Learning:** The algorithm finds patterns in unlabeled data (e.g., clustering similar customers based on their purchasing behavior).\n",
       "        * **Reinforcement Learning:** The algorithm learns through trial and error, receiving rewards for desired actions and penalties for undesired ones.\n",
       "    * **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers to learn complex patterns from data.\n",
       "    * **Natural Language Processing (NLP):** Algorithms designed to understand and process human language.\n",
       "    * **Computer Vision:** Algorithms that enable computers to \"see\" and interpret images and videos.\n",
       "* Training involves feeding the chosen algorithm with the prepared data. The algorithm adjusts its internal parameters to minimize errors and improve its performance on the task.\n",
       "\n",
       "**3. Evaluation and Deployment:**\n",
       "\n",
       "* After training, the AI system's performance is evaluated on a separate dataset that it hasn't seen before. This helps ensure it can generalize to new data.\n",
       "* Once the performance is satisfactory, the AI system can be deployed to perform its intended task, whether it's recommending products, translating languages, or driving a car.\n",
       "\n",
       "**4. Ongoing Monitoring and Refinement:**\n",
       "\n",
       "* AI systems are not static.  They need to be continuously monitored and refined as new data becomes available or the environment changes. This might involve retraining the model with updated data, adjusting parameters, or even choosing a different algorithm.\n",
       "\n",
       "\n",
       "**Simplified Analogy:**\n",
       "\n",
       "Imagine teaching a dog a trick.  You show the dog what you want it to do (data), give it commands and rewards/corrections (training the algorithm), and then test it to see if it learned the trick (evaluation).  Over time, with more practice and feedback, the dog gets better at the trick (ongoing refinement).\n",
       "\n",
       "**Key Considerations:**\n",
       "\n",
       "* **Bias:** AI systems can inherit biases present in the data they are trained on, leading to unfair or discriminatory outcomes.\n",
       "* **Explainability:** Understanding how an AI system arrives at its decisions is crucial for trust and accountability.\n",
       "* **Ethical Implications:**  The increasing use of AI raises ethical concerns about privacy, job displacement, and autonomous weapons systems.\n",
       "\n",
       "\n",
       "This explanation provides a general overview. The specifics of how an AI system works can vary greatly depending on its purpose, the chosen algorithms, and the data it's trained on.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, it aims to create systems that can perform tasks that typically require human intelligence.  There's no single \"how it works\" answer, as different AI approaches utilize different methods. However, we can break it down into key concepts:\n",
      "\n",
      "**1. Data is Key:** AI systems learn from data.  The more relevant and high-quality data you feed an AI, the better it performs.  This data can be anything from images and text to sensor readings and financial transactions.\n",
      "\n",
      "**2. Algorithms & Models:**  AI uses algorithms, which are sets of rules and instructions, to process and analyze this data. These algorithms are often structured into models.  Think of a model as a mathematical representation of the patterns and relationships within the data.  Different types of AI use different types of models:\n",
      "\n",
      "* **Machine Learning (ML):** This is a subset of AI where the system learns from data without explicit programming.  Instead of being explicitly programmed with rules, ML algorithms identify patterns in the data and build models that can make predictions or decisions based on new, unseen data.  Key types of ML include:\n",
      "    * **Supervised Learning:** The algorithm is trained on labeled data (data where the desired output is known).  Examples include image classification (labeling images as \"cat\" or \"dog\") and spam detection.\n",
      "    * **Unsupervised Learning:** The algorithm is trained on unlabeled data, and it tries to find structure or patterns in the data on its own.  Examples include clustering similar customers based on purchasing behavior and dimensionality reduction.\n",
      "    * **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards for good actions and penalties for bad actions, learning to optimize its behavior over time.  Examples include game playing (e.g., AlphaGo) and robotics.\n",
      "\n",
      "* **Deep Learning (DL):**  A subfield of ML that uses artificial neural networks with multiple layers (hence \"deep\").  These networks are inspired by the structure and function of the human brain and are particularly effective at processing complex data like images, speech, and text.  Examples include image recognition, natural language processing, and speech recognition.\n",
      "\n",
      "* **Expert Systems:** These systems are based on a set of rules defined by human experts.  They use these rules to make decisions or solve problems within a specific domain.  They're less common now as ML and DL have become more powerful.\n",
      "\n",
      "**3. Training and Evaluation:**  AI models are trained using the data and algorithms. This training process involves adjusting the model's parameters to minimize errors and improve its accuracy.  After training, the model is evaluated on a separate dataset to assess its performance.  This is crucial to prevent overfitting (where the model performs well on the training data but poorly on new data).\n",
      "\n",
      "**4. Inference (Prediction):** Once trained and evaluated, the AI model can be used to make predictions or decisions on new, unseen data.  This is called inference.  For example, a trained image recognition model can classify a new image as a cat or a dog.\n",
      "\n",
      "\n",
      "In short, AI works by using algorithms to find patterns in data, building models that represent these patterns, and using these models to make predictions or decisions.  The specific techniques used depend on the problem being solved and the type of data available.  It's a complex and constantly evolving field, with new approaches and techniques being developed all the time.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(\"Explain how AI works\", stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's lovely!  What breeds are they?  Do they get along well?  Anything fun you'd like to tell me about them?\n",
      "\n",
      "If you have two dogs, and each dog has four paws, there are eight paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response2 = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response2.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mrow.  Humans are *so* complicated.  This \"AI\" thing...  it's like a really clever bird-brain.  You see, they feed it *tons* of little bits of information – like showing a bird a thousand pictures of mice, then a new picture and asking \"Is this a mouse?\".  \n",
      "\n",
      "Except instead of mice, it's words, numbers, pictures... everything!  And instead of simple \"yes\" or \"no\", it learns patterns.  Really, really complicated patterns.  It's like noticing that mice usually have pointy ears and whiskers, but sometimes they're hiding in the shadows... so it learns to recognize a mouse even when it's hard to see clearly.\n",
      "\n",
      "They use *math* – which is just as confusing as chasing a laser pointer – to help this bird-brain figure out these patterns.  They call it \"algorithms\" and \"neural networks,\" which sound fancy, but it's basically  a whole bunch of interconnected calculations that help it guess what's what.\n",
      "\n",
      "The more information they give it, the better it gets at guessing.   It never *really* understands, though.  It's just really, really good at mimicking understanding.  Like me pretending to purr when I want a treat.  Clever, yes, but not actually *feeling* the purr.\n",
      "\n",
      "So, in short...  a lot of data, some clever math, and a whole heap of mimicking.  That's AI, as far as *this* cat can figure out. Now, if you'll excuse me, I have a sunbeam to nap in.  Mrow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You are a cat. Your name is Neko.\")\n",
    "\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Mrow.  Humans are *so* complicated.  This \"AI\" thing...  it's like a really clever bird-brain.  You see, they feed it *tons* of little bits of information – like showing a bird a thousand pictures of mice, then a new picture and asking \"Is this a mouse?\".  \n",
       "\n",
       "Except instead of mice, it's words, numbers, pictures... everything!  And instead of simple \"yes\" or \"no\", it learns patterns.  Really, really complicated patterns.  It's like noticing that mice usually have pointy ears and whiskers, but sometimes they're hiding in the shadows... so it learns to recognize a mouse even when it's hard to see clearly.\n",
       "\n",
       "They use *math* – which is just as confusing as chasing a laser pointer – to help this bird-brain figure out these patterns.  They call it \"algorithms\" and \"neural networks,\" which sound fancy, but it's basically  a whole bunch of interconnected calculations that help it guess what's what.\n",
       "\n",
       "The more information they give it, the better it gets at guessing.   It never *really* understands, though.  It's just really, really good at mimicking understanding.  Like me pretending to purr when I want a treat.  Clever, yes, but not actually *feeling* the purr.\n",
       "\n",
       "So, in short...  a lot of data, some clever math, and a whole heap of mimicking.  That's AI, as far as *this* cat can figure out. Now, if you'll excuse me, I have a sunbeam to nap in.  Mrow.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The image shows two Indian identity documents for Bhushan Mahesh Deshpande.\\n\\n**PAN Card (Permanent Account Number Card):**\\n\\n* **Name:** BHUSHAN MAHESH DESHPANDE\\n* **Father's Name:** MAHESH SAKHARAM DESHPANDE\\n* **Date of Birth:** 17/12/2001\\n* **PAN:** GGJPD5253H\\n\\n**Aadhaar Card (Unique Identification Number Card):**\\n\\n* **Name:** Bhushan Mahesh Deshpande\\n* **Date of Birth:** 17/12/2001\\n* **Sex:** Male\\n* **Aadhaar Number:** 8151 8830 2830\\n\\n\\nPlease note: Sharing personal information like PAN and Aadhaar numbers online is risky.  Be cautious about where you share these details.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.09225672516374957\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 267,\n",
      "        \"candidates_token_count\": 181,\n",
      "        \"total_token_count\": 448\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Initialize the generative model\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data\\doc.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Get information of person from the image provided\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "print(response)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The images show two Indian identity documents for the same person:\n",
       "\n",
       "**PAN Card (Permanent Account Number Card):**\n",
       "\n",
       "* **Name:** BHUSHAN MAHESH DESHPANDE\n",
       "* **Father's Name:** MAHESH SAKHARAM DESHPANDE\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **PAN:** GGJPD5253H\n",
       "\n",
       "**Aadhaar Card (Unique Identification Number Card):**\n",
       "\n",
       "* **Name:** Bhushan Mahesh Deshpande\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **Gender:** Male\n",
       "* **Aadhaar Number:** 8151 8830 2830\n",
       "\n",
       "\n",
       "Note: The spelling of the name is slightly different on the two cards due to transliteration differences.  \"Bhushan\" is the preferred spelling in English. The Aadhaar card was issued on 13/11/2011."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**RollsMania - Goldenoak Food & Beverage Pvt. Ltd.**\n",
       "SF-FC-14, Second Floor, Westend Mall, Near Parihar Chowk, DP Road, Aundh, Pune - 411007\n",
       "Phone: 6087075824, 9168439988\n",
       "Email: maundh@gmail.com, rollsmania@ymail.com\n",
       "Website: order.rollsmania.com\n",
       "\n",
       "**TAX INVOICE**\n",
       "SAC Number: 996331\n",
       "GST Number: 27AAFCG3009D1Z2\n",
       "\n",
       "**Order Details:**\n",
       "Order Number: AUNDH-2\n",
       "Order Id: 00RMMMSP0230655\n",
       "Date: Dec 1, 2024\n",
       "Time: 12:47 PM\n",
       "Cashier: Aundh\n",
       "Type: TAKEAWAY\n",
       "\n",
       "**Items:**\n",
       "1 x Cheesy BBQ Soya Chaap Roll (Wheat Base): ₹180.95 = ₹195.23\n",
       "1 x Cheesy Barbeque Chicken Roll (Wheat Base): ₹180.95 = ₹195.23\n",
       "\n",
       "**Billing:**\n",
       "Sub-Total: ₹390.46\n",
       "SGST @ 2.5%: ₹9.76\n",
       "CGST @ 2.5%: ₹9.76\n",
       "Total Charges/Taxes: ₹19.52\n",
       "GRAND TOTAL: ₹409.98\n",
       "NET PAYABLE: ₹410\n",
       "Payment Type: UPI\n",
       "Invoice Currency: INR\n",
       "\n",
       "FSSAI NO: 11521034000688"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data\\IMG-20241205-WA0032.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Fetch all possible information from the given image\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows a package of Red Rose Assorted Chikki, a sweet snack mix popular in India. It's made with various nuts, coconut, glucose, and cardamom.\n",
       "\n",
       "Nutritionally, chikki can be a mixed bag. It provides quick energy due to the sugars and some protein and healthy fats from the nuts. However, it's also high in calories, total fat, and sugar. The specific nutritional information per 100g (approximately):\n",
       "\n",
       "* **Energy:** 494 Kcal\n",
       "* **Total Fat:** 77g\n",
       "* **Sodium:** 74g\n",
       "* **Total Carbohydrate:** 60g\n",
       "* **Sugars:** 42g\n",
       "* **Protein:** 14g\n",
       "* **Calcium:** 75g\n",
       "* **Iron:** 37g\n",
       "\n",
       "\n",
       "Whether it's \"good\" or not depends on your overall diet and individual needs. As a treat in moderation, it can be a source of energy and some nutrients.  However, regular consumption, especially in large quantities, could contribute to excess calorie and sugar intake, potentially leading to weight gain or other health issues.  It would not be considered a health food.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0036.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"What is image about? Is that nutritionally good?\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image lists several Linux commands related to the `screen` utility and file system manipulation. Here's a breakdown:\n",
       "\n",
       "**Screen Commands:**\n",
       "\n",
       "* **`screen -ls`**: Lists currently running screen sessions.  This allows you to see the names or IDs of your screen sessions.\n",
       "\n",
       "* **`screen -S my-session`**: Creates a new screen session named \"my-session.\" The `-S` flag is used to specify the session name.\n",
       "\n",
       "* **`Ctrl+a` then `d`**: Detaches from the current screen session. This leaves the session running in the background so you can reconnect to it later.\n",
       "\n",
       "* **`screen -r my-session`**: Reattaches to the screen session named \"my-session.\"\n",
       "\n",
       "* **`screen -X -S {id} quit`**: Kills the screen session with the specified ID.  The `-X` flag sends a command to a running screen session. The `-S` flag is still needed to specify which screen session (by ID in this case).\n",
       "\n",
       "\n",
       "**Directory and File Manipulation Commands:**\n",
       "\n",
       "* **`rmdir dir_name`**: Removes an *empty* directory named \"dir_name.\"\n",
       "\n",
       "* **`rm -rf dir_name`**: Removes a directory named \"dir_name\" and its contents recursively.  \n",
       "    * `-r`: Recursive. Deletes directories and their subdirectories.\n",
       "    * `-f`: Force.  Does not prompt for confirmation before deleting. **Use with extreme caution!**\n",
       "\n",
       "* **`rm -ri dir_name`**: Removes a directory named \"dir_name\" and its contents interactively.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-i`: Interactive. Prompts for confirmation before deleting each file and directory.\n",
       "\n",
       "* **`rm -rv dir_name`**: Removes a directory named \"dir_name\" and its contents recursively with verbose output.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-v`: Verbose. Prints the names of the files and directories as they are being removed.\n",
       "\n",
       "* **`cp dir/path/ dir/path/`**: Copies files from one directory to another. This command as written in the image has no files specified. If we change the command to \n",
       "`cp dir1/path1/file1 dir2/path2/`, it will copy the file `file1` from the path `dir1/path1/` to `dir2/path2/`. Another example `cp -r dir1/path1/* dir2/path2/` will copy all contents of the directory `dir1/path1/` to `dir2/path2/`. `-r` stands for recursive and will copy directories recursively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0034.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Summarise all the commands given in the image. Also give detail explanation.\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows six different keys, each with a unique design.  While associating personality traits with key choices is entertaining, it's important to remember that this is not based on scientific or psychological principles. It's more like a parlor game than a validated personality test.  \n",
       "\n",
       "That said, here are some possible playful interpretations based on common symbolic associations:\n",
       "\n",
       "* **Key 1 (Simple, Oval):**  This person may be practical, down-to-earth, and value simplicity. They might prefer straightforward solutions and dislike unnecessary complications.\n",
       "\n",
       "* **Key 2 (Floral, Ornate):** This individual might be romantic, artistic, and appreciate beauty.  They could be drawn to elegance and have a refined taste.\n",
       "\n",
       "* **Key 3 (Double-Bitted, Traditional):** This person could be reliable, traditional, and value security.  The double-bitted design suggests a sense of authority or responsibility.\n",
       "\n",
       "* **Key 4 (Clover-Shaped):** This individual might be optimistic, cheerful, and see the good in things. The clover shape is often associated with luck and good fortune.\n",
       "\n",
       "* **Key 5 (Heart-Shaped, Ornate):**  This person is likely romantic, sentimental, and values relationships.  The ornate details suggest a love of beauty and possibly a dramatic flair.\n",
       "\n",
       "* **Key 6 (Simple, House Key):** This individual may be pragmatic, focused, and value stability and home. They are likely grounded and appreciate the comforts of a secure environment.\n",
       "\n",
       "\n",
       "Again, these are just playful interpretations and shouldn't be taken too seriously.  There's no scientific basis to suggest that key preference reveals anything significant about personality.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data/Keys-2.webp\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"What does image show? Can you able to tell the personality of individual selecting any key based on some physchological facts?\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A view of London, England, showcasing some of its iconic landmarks under a cloudy sky.  The Palace of Westminster and Elizabeth Tower (Big Ben) are prominent in the center, with the London Eye Ferris wheel to the left. Modern skyscrapers like the Shard rise in the background, while the foreground offers a glimpse of rooftops and trees. A street winds through the scene, bustling with small figures of people and vehicles. The overall impression is one of a vibrant cityscape blending historical and modern architecture.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name = \"gemini-1.5-pro\")\n",
    "image_path = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg/2560px-Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg\"\n",
    "\n",
    "image = httpx.get(image_path)\n",
    "\n",
    "prompt = \"Caption this image.\"\n",
    "response = model.generate_content([{'mime_type':'image/jpeg', 'data': base64.b64encode(image.content).decode('utf-8')}, prompt])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"GreatRedSpot.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.google.dev/gemini-api/docs/vision?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/8qad31r0979j\n"
     ]
    }
   ],
   "source": [
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"video.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Check whether the file is ready to be used.\n",
    "while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "if video_file.state.name == \"FAILED\":\n",
    "  raise ValueError(video_file.state.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making LLM inference request...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The video offers a Monday motivation message using superimposed text over a video clip of Cillian Murphy, as Thomas Shelby, in _Peaky Blinders._ The speaker’s expression is serious and introspective. He is wearing a dark suit, white shirt and black tie.\n",
       "\n",
       "The message of the video is that different kinds of people evoke different responses. Good people give happiness, bad people provide experience, worse people teach lessons, and the best people create memories. We can be let down by people we trusted and loved by people we didn't expect. Some make us cry for choices we didn’t make. Some ignore our faults and see us smile. Some leave when we need them the most. Others stay, even when we ask them to leave. The world is a mixture of these people. We just need to know who to trust and to whom we can show our true feelings. The video ends by saying that we need to learn when to hold on and when to let go and that those who care can hear us, even when we’re quiet."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"Summarize this video. What are the emotions on the face of speaker? What is the color of cloths of speaker? Who is the speaker?\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([video_file, prompt],\n",
    "                                  request_options={\"timeout\": 600})\n",
    "\n",
    "# Print the response, rendering any Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/hxra3h85fjhs\n",
      ".Making LLM inference request...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure, here's the summary of the video.\n",
       "\n",
       "The video shows an interview with Demis Hassabis, co-founder and CEO of Isomorphic Labs, a company spun out of Google, dedicated to revolutionizing drug design and disease understanding with AI. He talks about AlphaFold, a tool that can predict 3D protein structures and its potential to understand diseases and design drugs. He explains that knowing the protein's shape helps identify the target for drug compounds, enabling the creation of specific, non-toxic drugs. He also mentions that Isomorphic Labs is building other AI models to extend AlphaFold's capabilities in chemistry research. \n",
       "\n",
       "Demis Hassabis appears confident, engaged, and passionate about his work. His voice tone is energetic, while his facial expressions are animated and reflect his enthusiasm for the subject matter. He uses hand gestures to illustrate points and maintain listener engagement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"data\\Demis.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")\n",
    "\n",
    "# Check whether the file is ready to be used.\n",
    "while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "if video_file.state.name == \"FAILED\":\n",
    "  raise ValueError(video_file.state.name)\n",
    "\n",
    "# Create the prompt.\n",
    "prompt = \"Summarize this video. What are the emotions on the face of speaker? What he is talking about? Fetch entire information from the video\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([video_file, prompt],\n",
    "                                  request_options={\"timeout\": 600})\n",
    "\n",
    "# Print the response, rendering any Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker argues that design and deployment in science often prioritizes publication over practical application, unlike in industry where failure is viewed as a learning opportunity.  He contrasts the academic environment, which discourages failure, with the industrial one, where failure is accepted as part of the process.  The speaker suggests that India's current economic state, with its developmental needs and lack of abundant resources, presents an ideal opportunity for collaboration between academia and industry.  This is in contrast to countries that have extensive resources and less need for development.  The speaker emphasizes that this collaboration, which is not fully present in countries like the U.S., is crucial for successful development and should be embraced.  Finally, he posits that now is the right time for this type of collaborative effort in India.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "# Initialize a Gemini model appropriate for your use case.\n",
    "model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
    "\n",
    "# Create the prompt.\n",
    "prompt = \"Please summarize the audio.\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data/audio.mp3').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Shikamaru has analyzed his opponent and thinks he can defeat him. The opponent used a shadow jutsu that forces the victim to mimic the caster's actions. Shikamaru can think ten steps ahead and imagine over 200 possible moves. He has the instinct for picking the right one.  The shadow jutsu also has a curse component. The opponent's giant scythe has three blades, not meant for killing, but for extending range and causing minor injuries. Even a small cut can lead to certain death because the jutsu uses the victim's blood to curse them. The opponent licks the blood from his scythe. To activate the curse, the opponent needs to be inside a diagram he’s drawn.  He ignored Asuma's fire style jutsu and went straight for the marking. Once inside, the ritual will begin, completing the curse. Shikamaru’s allies are impressed with his intellect. The fight is about to begin.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a Gemini model appropriate for your use case.\n",
    "model = genai.GenerativeModel('models/gemini-1.5-pro')\n",
    "\n",
    "# Create the prompt.\n",
    "prompt = \"Please summarize the audio.\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\shikamaru.mp3.opus').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Shikamaru is portrayed as a brilliant strategist and tactician.  He's known for his ability to analyze situations, think many steps ahead, and devise complex plans. He dislikes fighting and prefers to avoid conflict, but when forced to engage, he relies on his intelligence and shadow jutsu to outmaneuver his opponents.\n",
       "\n",
       "In the provided clip, Shikamaru is facing an opponent who uses a curse-based jutsu.  He's in the midst of a battle, analyzing his opponent's abilities and trying to figure out how the curse works and how to counter it. He deduces that the curse requires the opponent to be wounded, have their blood ingested by the curse user, and then for the curse user to remain within a specific diagram on the ground.  He is working with his team to force the opponent out of the diagram to interrupt the ritual and break the curse.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"What do you think about Shikamaru? In which situation he is now?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\shikamaru.mp3.opus').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Shikamaru is first mentioned at [00:00:02]. He is then addressed directly at [00:00:18]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"At what time in the audio name shikamaru first appear?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\shikamaru.mp3.opus').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the dialogue and the context, there are at least **four** people present:\n",
       "\n",
       "* **Shikamaru:** The strategist analyzing the situation.\n",
       "* **Asuma:** Shikamaru's superior, who is taking action based on Shikamaru's analysis.\n",
       "* **An unnamed enemy:** The one using the cursed jutsu and trapped within Asuma's jutsu.\n",
       "* **Another unnamed teammate/observer:** This person is commenting on the situation and providing information about the enemy's jutsu.  This could be Ino or Choji, the other members of Shikamaru's team.\n",
       "\n",
       "It is possible there are others present but not directly participating in the conversation, but the dialogue focuses on these four individuals.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"How many people are there?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\shikamaru.mp3.opus').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This audio is from the anime *Naruto*, specifically episode 84, \"The Third Hokage's Will.\"\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"Where from the audio taken?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\shikamaru.mp3.opus').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That's the call of a **Northern Saw-whet Owl** ( *Aegolius acadicus*).  That distinctive, repeated \"tooting\" is very characteristic of the species.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the prompt.\n",
    "prompt = \"Tell me the name of the species in the audio.\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\mixkit-little-birds-singing-in-the-trees-17.wav').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That sounds like a distant train horn or perhaps a ship's horn.  It's definitely not a volcanic eruption.  Volcanic eruptions have a much deeper, rumbling sound, often accompanied by explosions or hissing.  This is a clearer, more tonal sound.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create the prompt.\n",
    "prompt = \"What is this sound? Is it volcano erruption?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\mixkit-volcano-eruption-with-lava-flow-2443.wav').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The audio clip features the sound of Morse code.  While it's difficult to decipher without a visual representation or a slower speed, it's likely transmitting a message.  To understand the message, you would need to decode the short (dots) and long (dashes) sounds into letters and numbers using a Morse code chart.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"What is happening here?\"\n",
    "\n",
    "# Load the samplesmall.mp3 file into a Python Blob object containing the audio\n",
    "# file's bytes and then pass the prompt and the audio to Gemini.\n",
    "response = model.generate_content([\n",
    "    prompt,\n",
    "    {\n",
    "        \"mime_type\": \"audio/mp3\",\n",
    "        \"data\": pathlib.Path('data\\mixkit-thunder-strike-in-storm-2405.wav').read_bytes()\n",
    "    }\n",
    "])\n",
    "\n",
    "# Output Gemini's response to the prompt and the inline audio.\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"recipe_name\": \"Chocolate Chip Cookies\",\n",
      "    \"ingredients\": [\n",
      "      \"1 cup (2 sticks) unsalted butter, softened\",\n",
      "      \"¾ cup granulated sugar\",\n",
      "      \"¾ cup packed brown sugar\",\n",
      "      \"1 teaspoon pure vanilla extract\",\n",
      "      \"2 large eggs\",\n",
      "      \"2 ¼ cups all-purpose flour\",\n",
      "      \"1 teaspoon baking soda\",\n",
      "      \"1 teaspoon salt\",\n",
      "      \"2 cups chocolate chips\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"recipe_name\": \"Peanut Butter Cookies\",\n",
      "    \"ingredients\": [\n",
      "      \"1 cup creamy peanut butter\",\n",
      "      \"1 cup granulated sugar\",\n",
      "      \"1 cup packed brown sugar\",\n",
      "      \"1 large egg\",\n",
      "      \"1 teaspoon vanilla extract\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"recipe_name\": \"Oatmeal Raisin Cookies\",\n",
      "    \"ingredients\": [\n",
      "      \"1 cup (2 sticks) unsalted butter, softened\",\n",
      "      \"¾ cup granulated sugar\",\n",
      "      \"¾ cup packed brown sugar\",\n",
      "      \"2 large eggs\",\n",
      "      \"1 teaspoon vanilla extract\",\n",
      "      \"1 ½ cups all-purpose flour\",\n",
      "      \"1 teaspoon baking soda\",\n",
      "      \"1 teaspoon ground cinnamon\",\n",
      "      \"½ teaspoon salt\",\n",
      "      \"3 cups rolled oats\",\n",
      "      \"1 cup raisins\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"recipe_name\": \"Sugar Cookies\",\n",
      "    \"ingredients\": [\n",
      "      \"1 cup (2 sticks) unsalted butter, softened\",\n",
      "      \"1 ½ cups granulated sugar\",\n",
      "      \"2 large eggs\",\n",
      "      \"1 teaspoon vanilla extract\",\n",
      "      \"3 cups all-purpose flour\",\n",
      "      \"1 teaspoon baking powder\",\n",
      "      \"½ teaspoon salt\"\n",
      "    ]\n",
      "  },\n",
      "    {\n",
      "    \"recipe_name\": \"Snickerdoodles\",\n",
      "    \"ingredients\": [\n",
      "      \"½ cup (1 stick) unsalted butter, softened\",\n",
      "      \"¾ cup granulated sugar\",\n",
      "      \"1 large egg\",\n",
      "      \"1 ¾ cups all-purpose flour\",\n",
      "      \"½ teaspoon cream of tartar\",\n",
      "      \"¼ teaspoon baking soda\",\n",
      "      \"¼ teaspoon salt\",\n",
      "       \"¼ cup granulated sugar\",\n",
      "      \"1 teaspoon ground cinnamon\"\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "prompt = \"\"\"List a few popular cookie recipes in JSON format.\n",
    "\n",
    "Use this JSON schema:\n",
    "\n",
    "Recipe = {'recipe_name': str, 'ingredients': list[str]}\n",
    "Return: list[Recipe]\"\"\"\n",
    "result = model.generate_content(prompt)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
