{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, is a broad field aiming to create machines capable of performing tasks that typically require human intelligence.  There's no single way AI works, as it encompasses various approaches and techniques. Here's a simplified breakdown:\n",
      "\n",
      "**1. Data:**  AI systems learn from data.  The more relevant data they're fed, the better they perform. This data can be anything from text and images to sensor readings and financial transactions.\n",
      "\n",
      "**2. Algorithms:** These are the sets of rules and statistical models that process the data. They're like recipes that tell the AI how to interpret and learn from the information it receives. Common algorithms include:\n",
      "\n",
      "* **Machine Learning (ML):** Allows systems to learn from data without explicit programming.  ML algorithms identify patterns, make predictions, and improve their performance over time. Key types of ML include:\n",
      "    * **Supervised Learning:**  The algorithm is trained on labeled data (e.g., images tagged with the objects they depict).  It learns to map inputs to outputs and can then classify new, unseen data.\n",
      "    * **Unsupervised Learning:**  The algorithm analyzes unlabeled data to discover hidden patterns, relationships, and structures (e.g., clustering similar customer profiles).\n",
      "    * **Reinforcement Learning:**  The algorithm learns through trial and error by interacting with an environment. It receives rewards for desirable actions and penalties for undesirable ones, eventually learning optimal strategies (e.g., game playing).\n",
      "* **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers (hence \"deep\") to analyze complex data.  DL excels in areas like image recognition, natural language processing, and speech recognition.\n",
      "* **Natural Language Processing (NLP):**  Focuses on enabling computers to understand, interpret, and generate human language.  This powers chatbots, language translation, and sentiment analysis.\n",
      "* **Computer Vision:**  Enables computers to \"see\" and interpret images and videos, similar to how humans do.  This is used in applications like facial recognition, object detection, and medical image analysis.\n",
      "\n",
      "**3. Training:**  The process of feeding data to the algorithms so they can learn and improve. This involves adjusting the parameters of the algorithms to minimize errors and optimize performance.  The training process can be computationally intensive and require significant resources.\n",
      "\n",
      "**4. Inference:** Once trained, the AI system can use its learned knowledge to make predictions or decisions on new, unseen data. For example, a spam filter trained on millions of emails can then classify incoming emails as spam or not spam.\n",
      "\n",
      "**5. Evaluation:** The performance of an AI system is evaluated using various metrics depending on the task.  Accuracy, precision, recall, and F1-score are common examples.  Continuous evaluation and refinement are crucial for improving the system's performance over time.\n",
      "\n",
      "\n",
      "**In summary:** AI systems learn from data using algorithms, are trained to optimize their performance, and then use their learned knowledge to make predictions or decisions. Different types of algorithms are used for different tasks, and the field is constantly evolving with new techniques and approaches being developed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyAFh8A_lni_FzoSQl0U3AtqbPP4NWWS7-Q\")\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The images show two Indian identity documents for the same person:\\n\\n**PAN Card (Permanent Account Number Card):**\\n\\n* **Name:** BHUSHAN MAHESH DESHPANDE\\n* **Father's Name:** MAHESH SAKHARAM DESHPANDE\\n* **Date of Birth:** 17/12/2001\\n* **PAN:** GGJPD5253H\\n\\n**Aadhaar Card (Unique Identification Number Card):**\\n\\n* **Name:** Bhushan Mahesh Deshpande\\n* **Date of Birth:** 17/12/2001\\n* **Gender:** Male\\n* **Aadhaar Number:** 8151 8830 2830\\n\\n\\nNote: The spelling of the name is slightly different on the two cards due to transliteration differences.  \\\"Bhushan\\\" is the preferred spelling in English. The Aadhaar card was issued on 13/11/2011.\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.12515309526415294\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 267,\n",
      "        \"candidates_token_count\": 203,\n",
      "        \"total_token_count\": 470\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Initialize the generative model\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"C:/Users/Admin/OneDrive/Desktop/Gemini/doc.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Get information of person from the image provided\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "print(response)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The images show two Indian identity documents for the same person:\n",
       "\n",
       "**PAN Card (Permanent Account Number Card):**\n",
       "\n",
       "* **Name:** BHUSHAN MAHESH DESHPANDE\n",
       "* **Father's Name:** MAHESH SAKHARAM DESHPANDE\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **PAN:** GGJPD5253H\n",
       "\n",
       "**Aadhaar Card (Unique Identification Number Card):**\n",
       "\n",
       "* **Name:** Bhushan Mahesh Deshpande\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **Gender:** Male\n",
       "* **Aadhaar Number:** 8151 8830 2830\n",
       "\n",
       "\n",
       "Note: The spelling of the name is slightly different on the two cards due to transliteration differences.  \"Bhushan\" is the preferred spelling in English. The Aadhaar card was issued on 13/11/2011."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Rolls Mania - Goldenoak Food & Beverage Pvt. Ltd.**\n",
       "SF-FC-14, Second Floor, Westend Mall, Near\n",
       "Parihar Chowk, DP Road, Aundh, Pune - 411007\n",
       "Phone: 6087075824, 9168439988\n",
       "Email: maundh@gmail.com, rollsmania@ymail.com\n",
       "Website: order.rollsmania.com\n",
       "\n",
       "**TAX INVOICE**\n",
       "SAC Number: 996331\n",
       "GST Number: 27AAFCG3009D1Z2\n",
       "\n",
       "**Order Details:**\n",
       "* **Order Type:** Takeaway\n",
       "* **Date & Time:** December 1, 2024, 12:47 PM\n",
       "* **Cashier:** Aundh\n",
       "* **Invoice No.:** 00RMMMSP0230655\n",
       "* **Order Number:** AUNDH-2\n",
       "* **Order ID:** 00RMMMSP0230655\n",
       "\n",
       "**Items Ordered:**\n",
       "* 1 x Cheesy BBQ Soya Chaap Roll (with Wheat Base) - ₹180.95\n",
       "* 1 x Cheesy Barbeque Chicken Roll (with Wheat Base) - ₹180.95\n",
       "\n",
       "**Bill Breakdown:**\n",
       "* **Subtotal:** ₹390.46\n",
       "* **SGST (2.5%):** ₹9.76\n",
       "* **CGST (2.5%):** ₹9.76\n",
       "* **Total Taxes/Charges:** ₹19.52\n",
       "* **Grand Total:** ₹409.98\n",
       "* **Net Payable:** ₹410\n",
       "* **Payment Type:** UPI\n",
       "* **Currency:** INR\n",
       "\n",
       "**FSSAI No.:** 11521034000688"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0032.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Fetch all possible information from the given image\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows a package of Red Rose Assorted Chikki, a sweet snack mix popular in India. It's made with various nuts, coconut, glucose, and cardamom.\n",
       "\n",
       "Nutritionally, chikki can be a mixed bag. It provides quick energy due to the sugars and some protein and healthy fats from the nuts. However, it's also high in calories, total fat, and sugar. The specific nutritional information per 100g (approximately):\n",
       "\n",
       "* **Energy:** 494 Kcal\n",
       "* **Total Fat:** 77g\n",
       "* **Sodium:** 74g\n",
       "* **Total Carbohydrate:** 60g\n",
       "* **Sugars:** 42g\n",
       "* **Protein:** 14g\n",
       "* **Calcium:** 75g\n",
       "* **Iron:** 37g\n",
       "\n",
       "\n",
       "Whether it's \"good\" or not depends on your overall diet and individual needs. As a treat in moderation, it can be a source of energy and some nutrients.  However, regular consumption, especially in large quantities, could contribute to excess calorie and sugar intake, potentially leading to weight gain or other health issues.  It would not be considered a health food.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0036.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"What is image about? Is that nutritionally good?\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image lists several Linux commands related to the `screen` utility and file system manipulation. Here's a breakdown:\n",
       "\n",
       "**Screen Commands:**\n",
       "\n",
       "* **`screen -ls`**: Lists currently running screen sessions.  This allows you to see the names or IDs of your screen sessions.\n",
       "\n",
       "* **`screen -S my-session`**: Creates a new screen session named \"my-session.\" The `-S` flag is used to specify the session name.\n",
       "\n",
       "* **`Ctrl+a` then `d`**: Detaches from the current screen session. This leaves the session running in the background so you can reconnect to it later.\n",
       "\n",
       "* **`screen -r my-session`**: Reattaches to the screen session named \"my-session.\"\n",
       "\n",
       "* **`screen -X -S {id} quit`**: Kills the screen session with the specified ID.  The `-X` flag sends a command to a running screen session. The `-S` flag is still needed to specify which screen session (by ID in this case).\n",
       "\n",
       "\n",
       "**Directory and File Manipulation Commands:**\n",
       "\n",
       "* **`rmdir dir_name`**: Removes an *empty* directory named \"dir_name.\"\n",
       "\n",
       "* **`rm -rf dir_name`**: Removes a directory named \"dir_name\" and its contents recursively.  \n",
       "    * `-r`: Recursive. Deletes directories and their subdirectories.\n",
       "    * `-f`: Force.  Does not prompt for confirmation before deleting. **Use with extreme caution!**\n",
       "\n",
       "* **`rm -ri dir_name`**: Removes a directory named \"dir_name\" and its contents interactively.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-i`: Interactive. Prompts for confirmation before deleting each file and directory.\n",
       "\n",
       "* **`rm -rv dir_name`**: Removes a directory named \"dir_name\" and its contents recursively with verbose output.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-v`: Verbose. Prints the names of the files and directories as they are being removed.\n",
       "\n",
       "* **`cp dir/path/ dir/path/`**: Copies files from one directory to another. This command as written in the image has no files specified. If we change the command to \n",
       "`cp dir1/path1/file1 dir2/path2/`, it will copy the file `file1` from the path `dir1/path1/` to `dir2/path2/`. Another example `cp -r dir1/path1/* dir2/path2/` will copy all contents of the directory `dir1/path1/` to `dir2/path2/`. `-r` stands for recursive and will copy directories recursively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0034.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Summarise all the commands given in the image. Also give detail explanation.\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.google.dev/gemini-api/docs/vision?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/8qad31r0979j\n"
     ]
    }
   ],
   "source": [
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"video.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Check whether the file is ready to be used.\n",
    "while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "if video_file.state.name == \"FAILED\":\n",
    "  raise ValueError(video_file.state.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making LLM inference request...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The video offers a Monday motivation message using superimposed text over a video clip of Cillian Murphy, as Thomas Shelby, in _Peaky Blinders._ The speaker’s expression is serious and introspective. He is wearing a dark suit, white shirt and black tie.\n",
       "\n",
       "The message of the video is that different kinds of people evoke different responses. Good people give happiness, bad people provide experience, worse people teach lessons, and the best people create memories. We can be let down by people we trusted and loved by people we didn't expect. Some make us cry for choices we didn’t make. Some ignore our faults and see us smile. Some leave when we need them the most. Others stay, even when we ask them to leave. The world is a mixture of these people. We just need to know who to trust and to whom we can show our true feelings. The video ends by saying that we need to learn when to hold on and when to let go and that those who care can hear us, even when we’re quiet."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"Summarize this video. What are the emotions on the face of speaker? What is the color of cloths of speaker? Who is the speaker?\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([video_file, prompt],\n",
    "                                  request_options={\"timeout\": 600})\n",
    "\n",
    "# Print the response, rendering any Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My files:\n",
      "   files/8qad31r0979j\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "print(\"My files:\")\n",
    "for f in genai.list_files():\n",
    "    print(\"  \", f.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
