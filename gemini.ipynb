{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import Markdown\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the generative model\n",
    "genai.configure(api_key=\"AIzaSyAFh8A_lni_FzoSQl0U3AtqbPP4NWWS7-Q\")\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) aims to mimic human cognitive functions like learning and problem-solving.  Here's a simplified breakdown of how it works:\n",
      "\n",
      "**1. Data Collection and Preparation:** AI systems are trained on vast amounts of data. This data can be anything: images, text, audio, sensor readings, etc. This data needs to be cleaned, organized, and formatted in a way the AI can understand. This often involves labeling data (e.g., tagging images with the objects they contain).\n",
      "\n",
      "**2. Choosing the Right Algorithm:**  Different AI tasks require different algorithms. Some common types include:\n",
      "\n",
      "* **Machine Learning (ML):** Algorithms that allow computers to learn from data without explicit programming.  Within ML, there are several key approaches:\n",
      "    * **Supervised Learning:** The AI is trained on labeled data, learning to map inputs to outputs (e.g., predicting house prices based on features like size and location).\n",
      "    * **Unsupervised Learning:** The AI explores unlabeled data, identifying patterns and relationships (e.g., clustering customers into different segments based on their purchasing behavior).\n",
      "    * **Reinforcement Learning:** The AI learns through trial and error, receiving rewards or penalties for its actions (e.g., training a robot to navigate a maze).\n",
      "* **Deep Learning (DL):** A subset of ML that uses artificial neural networks with multiple layers to analyze complex data.  These networks are inspired by the structure of the human brain and are particularly effective for tasks like image recognition and natural language processing.\n",
      "* **Natural Language Processing (NLP):**  Focuses on enabling computers to understand, interpret, and generate human language.\n",
      "* **Computer Vision:** Enables computers to \"see\" and interpret images and videos, similar to how humans do.\n",
      "\n",
      "**3. Training the Model:** The chosen algorithm is fed the prepared data. During training, the algorithm adjusts its internal parameters to minimize errors and improve its performance on the given task.  This process can be computationally intensive and require specialized hardware like GPUs.\n",
      "\n",
      "**4. Evaluation and Tuning:** After training, the AI model is evaluated on a separate dataset to assess its performance.  Metrics like accuracy, precision, and recall are used to measure how well the model generalizes to unseen data.  If the performance is not satisfactory, the model can be further tuned by adjusting parameters, changing the algorithm, or using more data.\n",
      "\n",
      "**5. Deployment and Prediction:** Once the model meets the desired performance criteria, it can be deployed to make predictions on new, unseen data.  For example, a trained image recognition model could be integrated into a self-driving car to identify pedestrians and other objects.\n",
      "\n",
      "**6. Ongoing Monitoring and Improvement:** AI models are not static.  Their performance can degrade over time as the real-world data changes.  Therefore, it's crucial to continuously monitor the model's performance and retrain it periodically with new data to maintain accuracy and relevance.\n",
      "\n",
      "\n",
      "**In simple terms, AI works by learning patterns from data and using those patterns to make predictions or decisions.  The complexity of the AI system depends on the task it's designed to perform and the amount and quality of the data it's trained on.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "response = model.generate_content(\"Explain how AI works\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The image shows two Indian identity documents for Bhushan Mahesh Deshpande.\\n\\n**PAN Card (Permanent Account Number Card):**\\n\\n* **Name:** BHUSHAN MAHESH DESHPANDE\\n* **Father's Name:** MAHESH SAKHARAM DESHPANDE\\n* **Date of Birth:** 17/12/2001\\n* **PAN:** GGJPD5253H\\n\\n**Aadhaar Card (Unique Identification Number Card):**\\n\\n* **Name:** Bhushan Mahesh Deshpande\\n* **Date of Birth:** 17/12/2001\\n* **Sex:** Male\\n* **Aadhaar Number:** 8151 8830 2830\\n\\n\\nPlease note: Sharing personal information like PAN and Aadhaar numbers online is risky.  Be cautious about where you share these details.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.09225672516374957\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 267,\n",
      "        \"candidates_token_count\": 181,\n",
      "        \"total_token_count\": 448\n",
      "      }\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "\n",
    "# Initialize the generative model\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data\\doc.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Get information of person from the image provided\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "print(response)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The images show two Indian identity documents for the same person:\n",
       "\n",
       "**PAN Card (Permanent Account Number Card):**\n",
       "\n",
       "* **Name:** BHUSHAN MAHESH DESHPANDE\n",
       "* **Father's Name:** MAHESH SAKHARAM DESHPANDE\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **PAN:** GGJPD5253H\n",
       "\n",
       "**Aadhaar Card (Unique Identification Number Card):**\n",
       "\n",
       "* **Name:** Bhushan Mahesh Deshpande\n",
       "* **Date of Birth:** 17/12/2001\n",
       "* **Gender:** Male\n",
       "* **Aadhaar Number:** 8151 8830 2830\n",
       "\n",
       "\n",
       "Note: The spelling of the name is slightly different on the two cards due to transliteration differences.  \"Bhushan\" is the preferred spelling in English. The Aadhaar card was issued on 13/11/2011."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**RollsMania - Goldenoak Food & Beverage Pvt. Ltd.**\n",
       "SF-FC-14, Second Floor, Westend Mall, Near Parihar Chowk, DP Road, Aundh, Pune - 411007\n",
       "Phone: 6087075824, 9168439988\n",
       "Email: maundh@gmail.com, rollsmania@ymail.com\n",
       "Website: order.rollsmania.com\n",
       "\n",
       "**TAX INVOICE**\n",
       "SAC Number: 996331\n",
       "GST Number: 27AAFCG3009D1Z2\n",
       "\n",
       "**Order Details:**\n",
       "Order Number: AUNDH-2\n",
       "Order Id: 00RMMMSP0230655\n",
       "Date: Dec 1, 2024\n",
       "Time: 12:47 PM\n",
       "Cashier: Aundh\n",
       "Type: TAKEAWAY\n",
       "\n",
       "**Items:**\n",
       "1 x Cheesy BBQ Soya Chaap Roll (Wheat Base): ₹180.95 = ₹195.23\n",
       "1 x Cheesy Barbeque Chicken Roll (Wheat Base): ₹180.95 = ₹195.23\n",
       "\n",
       "**Billing:**\n",
       "Sub-Total: ₹390.46\n",
       "SGST @ 2.5%: ₹9.76\n",
       "CGST @ 2.5%: ₹9.76\n",
       "Total Charges/Taxes: ₹19.52\n",
       "GRAND TOTAL: ₹409.98\n",
       "NET PAYABLE: ₹410\n",
       "Payment Type: UPI\n",
       "Invoice Currency: INR\n",
       "\n",
       "FSSAI NO: 11521034000688"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data\\IMG-20241205-WA0032.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Fetch all possible information from the given image\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows a package of Red Rose Assorted Chikki, a sweet snack mix popular in India. It's made with various nuts, coconut, glucose, and cardamom.\n",
       "\n",
       "Nutritionally, chikki can be a mixed bag. It provides quick energy due to the sugars and some protein and healthy fats from the nuts. However, it's also high in calories, total fat, and sugar. The specific nutritional information per 100g (approximately):\n",
       "\n",
       "* **Energy:** 494 Kcal\n",
       "* **Total Fat:** 77g\n",
       "* **Sodium:** 74g\n",
       "* **Total Carbohydrate:** 60g\n",
       "* **Sugars:** 42g\n",
       "* **Protein:** 14g\n",
       "* **Calcium:** 75g\n",
       "* **Iron:** 37g\n",
       "\n",
       "\n",
       "Whether it's \"good\" or not depends on your overall diet and individual needs. As a treat in moderation, it can be a source of energy and some nutrients.  However, regular consumption, especially in large quantities, could contribute to excess calorie and sugar intake, potentially leading to weight gain or other health issues.  It would not be considered a health food.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0036.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"What is image about? Is that nutritionally good?\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image lists several Linux commands related to the `screen` utility and file system manipulation. Here's a breakdown:\n",
       "\n",
       "**Screen Commands:**\n",
       "\n",
       "* **`screen -ls`**: Lists currently running screen sessions.  This allows you to see the names or IDs of your screen sessions.\n",
       "\n",
       "* **`screen -S my-session`**: Creates a new screen session named \"my-session.\" The `-S` flag is used to specify the session name.\n",
       "\n",
       "* **`Ctrl+a` then `d`**: Detaches from the current screen session. This leaves the session running in the background so you can reconnect to it later.\n",
       "\n",
       "* **`screen -r my-session`**: Reattaches to the screen session named \"my-session.\"\n",
       "\n",
       "* **`screen -X -S {id} quit`**: Kills the screen session with the specified ID.  The `-X` flag sends a command to a running screen session. The `-S` flag is still needed to specify which screen session (by ID in this case).\n",
       "\n",
       "\n",
       "**Directory and File Manipulation Commands:**\n",
       "\n",
       "* **`rmdir dir_name`**: Removes an *empty* directory named \"dir_name.\"\n",
       "\n",
       "* **`rm -rf dir_name`**: Removes a directory named \"dir_name\" and its contents recursively.  \n",
       "    * `-r`: Recursive. Deletes directories and their subdirectories.\n",
       "    * `-f`: Force.  Does not prompt for confirmation before deleting. **Use with extreme caution!**\n",
       "\n",
       "* **`rm -ri dir_name`**: Removes a directory named \"dir_name\" and its contents interactively.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-i`: Interactive. Prompts for confirmation before deleting each file and directory.\n",
       "\n",
       "* **`rm -rv dir_name`**: Removes a directory named \"dir_name\" and its contents recursively with verbose output.\n",
       "    * `-r`: Recursive (as above).\n",
       "    * `-v`: Verbose. Prints the names of the files and directories as they are being removed.\n",
       "\n",
       "* **`cp dir/path/ dir/path/`**: Copies files from one directory to another. This command as written in the image has no files specified. If we change the command to \n",
       "`cp dir1/path1/file1 dir2/path2/`, it will copy the file `file1` from the path `dir1/path1/` to `dir2/path2/`. Another example `cp -r dir1/path1/* dir2/path2/` will copy all contents of the directory `dir1/path1/` to `dir2/path2/`. `-r` stands for recursive and will copy directories recursively."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"IMG-20241205-WA0034.jpg\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"Summarise all the commands given in the image. Also give detail explanation.\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The image shows six different keys, each with a unique design.  While associating personality traits with key choices is entertaining, it's important to remember that this is not based on scientific or psychological principles. It's more like a parlor game than a validated personality test.  \n",
       "\n",
       "That said, here are some possible playful interpretations based on common symbolic associations:\n",
       "\n",
       "* **Key 1 (Simple, Oval):**  This person may be practical, down-to-earth, and value simplicity. They might prefer straightforward solutions and dislike unnecessary complications.\n",
       "\n",
       "* **Key 2 (Floral, Ornate):** This individual might be romantic, artistic, and appreciate beauty.  They could be drawn to elegance and have a refined taste.\n",
       "\n",
       "* **Key 3 (Double-Bitted, Traditional):** This person could be reliable, traditional, and value security.  The double-bitted design suggests a sense of authority or responsibility.\n",
       "\n",
       "* **Key 4 (Clover-Shaped):** This individual might be optimistic, cheerful, and see the good in things. The clover shape is often associated with luck and good fortune.\n",
       "\n",
       "* **Key 5 (Heart-Shaped, Ornate):**  This person is likely romantic, sentimental, and values relationships.  The ornate details suggest a love of beauty and possibly a dramatic flair.\n",
       "\n",
       "* **Key 6 (Simple, House Key):** This individual may be pragmatic, focused, and value stability and home. They are likely grounded and appreciate the comforts of a secure environment.\n",
       "\n",
       "\n",
       "Again, these are just playful interpretations and shouldn't be taken too seriously.  There's no scientific basis to suggest that key preference reveals anything significant about personality.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the image path (use raw string or double backslashes for Windows paths)\n",
    "image_path = r\"data/Keys-2.webp\"\n",
    "\n",
    "# Read the image file\n",
    "with open(image_path, \"rb\") as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Encode the image in base64\n",
    "encoded_image = base64.b64encode(image_data).decode(\"utf-8\")\n",
    "\n",
    "# Prepare the prompt and image input\n",
    "prompt = \"What does image show? Can you able to tell the personality of individual selecting any key based on some physchological facts?\"\n",
    "inputs = [{'mime_type': 'image/jpeg', 'data': encoded_image}, prompt]\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(inputs)\n",
    "\n",
    "# Print the generated response\n",
    "Markdown(response.text)  # Adjust if response needs specific method/attribute access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ai.google.dev/gemini-api/docs/vision?lang=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/8qad31r0979j\n"
     ]
    }
   ],
   "source": [
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"video.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Check whether the file is ready to be used.\n",
    "while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "if video_file.state.name == \"FAILED\":\n",
    "  raise ValueError(video_file.state.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making LLM inference request...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The video offers a Monday motivation message using superimposed text over a video clip of Cillian Murphy, as Thomas Shelby, in _Peaky Blinders._ The speaker’s expression is serious and introspective. He is wearing a dark suit, white shirt and black tie.\n",
       "\n",
       "The message of the video is that different kinds of people evoke different responses. Good people give happiness, bad people provide experience, worse people teach lessons, and the best people create memories. We can be let down by people we trusted and loved by people we didn't expect. Some make us cry for choices we didn’t make. Some ignore our faults and see us smile. Some leave when we need them the most. Others stay, even when we ask them to leave. The world is a mixture of these people. We just need to know who to trust and to whom we can show our true feelings. The video ends by saying that we need to learn when to hold on and when to let go and that those who care can hear us, even when we’re quiet."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt.\n",
    "prompt = \"Summarize this video. What are the emotions on the face of speaker? What is the color of cloths of speaker? Who is the speaker?\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([video_file, prompt],\n",
    "                                  request_options={\"timeout\": 600})\n",
    "\n",
    "# Print the response, rendering any Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file...\n",
      "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/hxra3h85fjhs\n",
      ".Making LLM inference request...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure, here's the summary of the video.\n",
       "\n",
       "The video shows an interview with Demis Hassabis, co-founder and CEO of Isomorphic Labs, a company spun out of Google, dedicated to revolutionizing drug design and disease understanding with AI. He talks about AlphaFold, a tool that can predict 3D protein structures and its potential to understand diseases and design drugs. He explains that knowing the protein's shape helps identify the target for drug compounds, enabling the creation of specific, non-toxic drugs. He also mentions that Isomorphic Labs is building other AI models to extend AlphaFold's capabilities in chemistry research. \n",
       "\n",
       "Demis Hassabis appears confident, engaged, and passionate about his work. His voice tone is energetic, while his facial expressions are animated and reflect his enthusiasm for the subject matter. He uses hand gestures to illustrate points and maintain listener engagement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Upload the video and print a confirmation.\n",
    "video_file_name = \"data\\Demis.mp4\"\n",
    "\n",
    "print(f\"Uploading file...\")\n",
    "video_file = genai.upload_file(path=video_file_name)\n",
    "print(f\"Completed upload: {video_file.uri}\")\n",
    "\n",
    "# Check whether the file is ready to be used.\n",
    "while video_file.state.name == \"PROCESSING\":\n",
    "    print('.', end='')\n",
    "    time.sleep(10)\n",
    "    video_file = genai.get_file(video_file.name)\n",
    "\n",
    "if video_file.state.name == \"FAILED\":\n",
    "  raise ValueError(video_file.state.name)\n",
    "\n",
    "# Create the prompt.\n",
    "prompt = \"Summarize this video. What are the emotions on the face of speaker? What he is talking about? Fetch entire information from the video\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([video_file, prompt],\n",
    "                                  request_options={\"timeout\": 600})\n",
    "\n",
    "# Print the response, rendering any Markdown\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
